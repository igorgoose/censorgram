{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pWFf_Cal9ATB",
    "outputId": "f65dbc34-ec06-4f9d-a4a0-03d2529f9d9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec  6 21:35:54 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZnXUK3hp61OM",
    "outputId": "e7ed5739-6fcd-47ea-8321-576de97e911d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
      "\u001B[K     |████████████████████████████████| 3.1 MB 9.1 MB/s \n",
      "\u001B[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001B[K     |████████████████████████████████| 3.3 MB 58.3 MB/s \n",
      "\u001B[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "\u001B[K     |████████████████████████████████| 895 kB 59.6 MB/s \n",
      "\u001B[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
      "\u001B[K     |████████████████████████████████| 61 kB 526 kB/s \n",
      "\u001B[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001B[K     |████████████████████████████████| 596 kB 54.0 MB/s \n",
      "\u001B[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n",
      "Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n",
      "Collecting torch==1.10.0+cu113\n",
      "  Downloading https://download.pytorch.org/whl/cu113/torch-1.10.0%2Bcu113-cp37-cp37m-linux_x86_64.whl (1821.5 MB)\n",
      "\u001B[K     |██████████████▋                 | 834.1 MB 1.4 MB/s eta 0:11:49tcmalloc: large alloc 1147494400 bytes == 0x5573f9c1e000 @  0x7f13154cf615 0x5573c068b4cc 0x5573c076b47a 0x5573c068e2ed 0x5573c077fe1d 0x5573c0701e99 0x5573c06fc9ee 0x5573c068fbda 0x5573c0701d00 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fe737 0x5573c0780c66 0x5573c06fddaf 0x5573c0780c66 0x5573c06fddaf 0x5573c0780c66 0x5573c06fddaf 0x5573c0690039 0x5573c06d3409 0x5573c068ec52 0x5573c0701c25 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fe737 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fd915 0x5573c068fafa 0x5573c06fdc0d 0x5573c06fc9ee\n",
      "\u001B[K     |██████████████████▌             | 1055.7 MB 1.2 MB/s eta 0:10:21tcmalloc: large alloc 1434370048 bytes == 0x55743e274000 @  0x7f13154cf615 0x5573c068b4cc 0x5573c076b47a 0x5573c068e2ed 0x5573c077fe1d 0x5573c0701e99 0x5573c06fc9ee 0x5573c068fbda 0x5573c0701d00 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fe737 0x5573c0780c66 0x5573c06fddaf 0x5573c0780c66 0x5573c06fddaf 0x5573c0780c66 0x5573c06fddaf 0x5573c0690039 0x5573c06d3409 0x5573c068ec52 0x5573c0701c25 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fe737 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fd915 0x5573c068fafa 0x5573c06fdc0d 0x5573c06fc9ee\n",
      "\u001B[K     |███████████████████████▌        | 1336.2 MB 1.3 MB/s eta 0:06:01tcmalloc: large alloc 1792966656 bytes == 0x5573c30a6000 @  0x7f13154cf615 0x5573c068b4cc 0x5573c076b47a 0x5573c068e2ed 0x5573c077fe1d 0x5573c0701e99 0x5573c06fc9ee 0x5573c068fbda 0x5573c0701d00 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fe737 0x5573c0780c66 0x5573c06fddaf 0x5573c0780c66 0x5573c06fddaf 0x5573c0780c66 0x5573c06fddaf 0x5573c0690039 0x5573c06d3409 0x5573c068ec52 0x5573c0701c25 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fe737 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fd915 0x5573c068fafa 0x5573c06fdc0d 0x5573c06fc9ee\n",
      "\u001B[K     |█████████████████████████████▊  | 1691.1 MB 1.3 MB/s eta 0:01:44tcmalloc: large alloc 2241208320 bytes == 0x55742de8e000 @  0x7f13154cf615 0x5573c068b4cc 0x5573c076b47a 0x5573c068e2ed 0x5573c077fe1d 0x5573c0701e99 0x5573c06fc9ee 0x5573c068fbda 0x5573c0701d00 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fe737 0x5573c0780c66 0x5573c06fddaf 0x5573c0780c66 0x5573c06fddaf 0x5573c0780c66 0x5573c06fddaf 0x5573c0690039 0x5573c06d3409 0x5573c068ec52 0x5573c0701c25 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fe737 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fd915 0x5573c068fafa 0x5573c06fdc0d 0x5573c06fc9ee\n",
      "\u001B[K     |████████████████████████████████| 1821.5 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 1821458432 bytes == 0x5574b37f0000 @  0x7f13154ce1e7 0x5573c06c1067 0x5573c068b4cc 0x5573c076b47a 0x5573c068e2ed 0x5573c077fe1d 0x5573c0701e99 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fdc0d 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fdc0d 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fdc0d 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fdc0d 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fdc0d 0x5573c068fafa 0x5573c06fdc0d 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fe737 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fe737 0x5573c06fc9ee\n",
      "tcmalloc: large alloc 2276827136 bytes == 0x557520104000 @  0x7f13154cf615 0x5573c068b4cc 0x5573c076b47a 0x5573c068e2ed 0x5573c077fe1d 0x5573c0701e99 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fdc0d 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fdc0d 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fdc0d 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fdc0d 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fdc0d 0x5573c068fafa 0x5573c06fdc0d 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fe737 0x5573c06fc9ee 0x5573c068fbda 0x5573c06fe737 0x5573c06fc9ee 0x5573c0690271\n",
      "\u001B[K     |████████████████████████████████| 1821.5 MB 5.8 kB/s \n",
      "\u001B[?25hCollecting torchvision==0.11.1+cu113\n",
      "  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.11.1%2Bcu113-cp37-cp37m-linux_x86_64.whl (24.6 MB)\n",
      "\u001B[K     |████████████████████████████████| 24.6 MB 1.6 MB/s \n",
      "\u001B[?25hCollecting torchaudio===0.10.0+cu113\n",
      "  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.10.0%2Bcu113-cp37-cp37m-linux_x86_64.whl (2.9 MB)\n",
      "\u001B[K     |████████████████████████████████| 2.9 MB 50.5 MB/s \n",
      "\u001B[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0+cu113) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.1+cu113) (1.19.5)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.1+cu113) (7.1.2)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.10.0+cu111\n",
      "    Uninstalling torch-1.10.0+cu111:\n",
      "      Successfully uninstalled torch-1.10.0+cu111\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.11.1+cu111\n",
      "    Uninstalling torchvision-0.11.1+cu111:\n",
      "      Successfully uninstalled torchvision-0.11.1+cu111\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.10.0+cu111\n",
      "    Uninstalling torchaudio-0.10.0+cu111:\n",
      "      Successfully uninstalled torchaudio-0.10.0+cu111\n",
      "Successfully installed torch-1.10.0+cu113 torchaudio-0.10.0+cu113 torchvision-0.11.1+cu113\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip3 install torch==1.10.0+cu113 torchvision==0.11.1+cu113 torchaudio===0.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
    "!python -m pip install --user numpy scipy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PxZtkJlu68hk",
    "outputId": "a3cb43f3-c9c3-438f-e1c0-9afbdb7a1043"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qzWRR6jY7UZQ"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments\n",
    "from transformers import Trainer\n",
    "from transformers.file_utils import cached_property\n",
    "from transformers.trainer_callback import EarlyStoppingCallback\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TI67Tixo7Vre"
   },
   "outputs": [],
   "source": [
    "class UnsafeDataset(Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tGJb_EwX6s7i"
   },
   "outputs": [],
   "source": [
    "def get_metrics(preds):\n",
    "    preds, labels = preds.predictions, preds.label_ids\n",
    "    # standard round approach\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    pr, rec, f, _ = precision_recall_fscore_support(labels, pred_flat, average='weighted')\n",
    "\n",
    "    print(\"precision\", pr)\n",
    "    print(\"recall\", rec)\n",
    "    print(\"fscore_weighted\", f)\n",
    "\n",
    "    # adjust threshold approach\n",
    "    preds_adj = np.array([[float(el1), float(el2)] for el1, el2 in preds])\n",
    "    preds_adj = softmax(preds_adj, axis=1)\n",
    "    roc_auc = roc_auc_score(labels, preds_adj[:, 1])\n",
    "    print(\"roc_auc\", roc_auc)\n",
    "\n",
    "    all_metrcis = []\n",
    "    for threshold in [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]:\n",
    "        metrcis = []\n",
    "        pred_labels = (preds_adj[:, 1] >= threshold).astype(int)\n",
    "        metrcis.append(threshold)\n",
    "        metrcis.append(round(f1_score(labels, pred_labels, average='weighted'), 2))\n",
    "        metrcis.append(round(precision_score(labels, pred_labels), 2))\n",
    "        metrcis.append(round(recall_score(labels, pred_labels), 2))\n",
    "        metrcis.append(round(accuracy_score(labels, pred_labels), 2))\n",
    "        all_metrcis.append(metrcis)\n",
    "\n",
    "    df_metrics = pd.DataFrame(data=all_metrcis, columns=['threshold', 'f1', 'prec', 'rec', 'acc'])\n",
    "    df_metrics = df_metrics.sort_values(by='f1', ascending=False)\n",
    "\n",
    "    print(classification_report(labels, pred_flat))\n",
    "\n",
    "    print(df_metrics.head())\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def compute_metrics(pred_):\n",
    "    labels = pred_.label_ids\n",
    "    preds = pred_.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 798,
     "referenced_widgets": [
      "6e4096557950488bb10e73010cc2246a",
      "88533516dfce441a8191ded1e9577ffc",
      "4ffe632561334d86849173ca7caa66e1",
      "fcf2c07e4ea7497e8e3829b106fb5903",
      "e29a1008dcc14277be4de71f50628774",
      "9a39210dc5804fa298cd9844b1510d11",
      "0e96feab70eb491bacfae4236dbf61b5",
      "5b81e7e5d1c44510a1d7499a7b6d9636",
      "b08370db97714bb89899f698087c4dce",
      "45346c93451840b8bcce1a388e3d9690",
      "04be287a310d416bbb685fd8902c0fc0"
     ]
    },
    "id": "jschmBeF4wAE",
    "outputId": "8f4861c1-55e2-4953-f0c3-4a5699debb97"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4096557950488bb10e73010cc2246a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/681M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased-conversational were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-conversational and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       inappropriate  offline_crime  ...  social_injustice  human_labeled\n",
      "count  130665.000000  130665.000000  ...     130665.000000  130665.000000\n",
      "mean        0.310579       0.048903  ...          0.046057       0.053924\n",
      "std         0.406632       0.215503  ...          0.209389       0.225869\n",
      "min         0.000000       0.000000  ...          0.000000       0.000000\n",
      "25%         0.000000       0.000000  ...          0.000000       0.000000\n",
      "50%         0.050000       0.000000  ...          0.000000       0.000000\n",
      "75%         0.760000       0.000000  ...          0.000000       0.000000\n",
      "max         1.000000       1.000000  ...          1.000000       1.000000\n",
      "\n",
      "[8 rows x 20 columns]\n",
      "       inappropriate  offline_crime  ...  social_injustice  human_labeled\n",
      "count   84903.000000   84903.000000  ...      84903.000000   84903.000000\n",
      "mean        0.257046       0.046145  ...          0.052667       0.053155\n",
      "std         0.437008       0.209605  ...          0.223103       0.224343\n",
      "min         0.000000       0.000000  ...          0.000000       0.000000\n",
      "25%         0.000000       0.000000  ...          0.000000       0.000000\n",
      "50%         0.000000       0.000000  ...          0.000000       0.000000\n",
      "75%         1.000000       0.000000  ...          0.000000       0.000000\n",
      "max         1.000000       1.000000  ...          1.000000       1.000000\n",
      "\n",
      "[8 rows x 20 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "model_name = 'DeepPavlov/rubert-base-cased-conversational'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "data_eval = pd.read_csv(\"val.csv\")\n",
    "data_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(data.describe())\n",
    "# print(data.columns)\n",
    "# print(data.info)\n",
    "\n",
    "# приводим датасет в порядок\n",
    "# фильтрация по ограничениям\n",
    "label_name = 'inappropriate'\n",
    "threshold = 0\n",
    "data = data[(data[label_name] >= 1 - threshold) | (data[label_name] <= threshold)]\n",
    "data_eval = data_eval[(data_eval[label_name] >= 1 - threshold) | (data_eval[label_name] <= threshold)]\n",
    "data_test = data_test[(data_test[label_name] >= 1 - threshold) | (data_test[label_name] <= threshold)]\n",
    "\n",
    "# окргуление до 0 или 1\n",
    "data[label_name] = data[label_name].apply(round)\n",
    "data_eval[label_name] = data_eval[label_name].apply(round)\n",
    "data_test[label_name] = data_test[label_name].apply(round)\n",
    "\n",
    "print(data.describe())\n",
    "\n",
    "train_dataset = UnsafeDataset(tokenizer(data.text.tolist(),\n",
    "                                        max_length=64,\n",
    "                                        truncation=True,\n",
    "                                        padding='longest'), data.inappropriate.tolist())\n",
    "\n",
    "eval_dataset = UnsafeDataset(tokenizer(data_eval.text.tolist(),\n",
    "                                       max_length=64,\n",
    "                                       truncation=True,\n",
    "                                       padding='longest'), data_eval.inappropriate.tolist())\n",
    "\n",
    "\n",
    "test_dataset = UnsafeDataset(tokenizer(data_test.text.tolist(),\n",
    "                                       max_length=64,\n",
    "                                       truncation=True,\n",
    "                                       padding='longest'), data_test.inappropriate.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_YNUSvGI5-BZ"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GCeBLu8fAdhN",
    "outputId": "0f5d7bfd-0c10-4e9b-d0e9-cdc65bebf832"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "O_foqJaz6WOV"
   },
   "outputs": [],
   "source": [
    "class TrAr(TrainingArguments):\n",
    "    @cached_property\n",
    "    def _setup_devices(self) -> Tuple[\"torch.device\", int]:\n",
    "        return device\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./unsafe/FINAL_VERS',  # output directory\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,  # total # of training epochs\n",
    "    per_device_train_batch_size=32,  # batch size per device during training\n",
    "    per_device_eval_batch_size=32,  # batch size for evaluation\n",
    "    warmup_steps=0,  # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=1e-8,  # strength of weight decay\n",
    "    learning_rate=2e-5,\n",
    "    save_total_limit=2,\n",
    "    logging_dir='./logs',  # directory for storing logs\n",
    "    logging_steps=2500,\n",
    "    eval_steps=2500,\n",
    "    save_steps=2500,\n",
    "    evaluation_strategy='steps', metric_for_best_model='f1', greater_is_better=True, load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,  # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,  # training arguments, defined above\n",
    "    train_dataset=train_dataset,  # training dataset\n",
    "    eval_dataset=eval_dataset,  # evaluation dataset\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.add_callback(EarlyStoppingCallback(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XU3Im9_w6cPO",
    "outputId": "684a3bf0-2660-483b-9990-233af101904c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jpWybMiT6dom",
    "outputId": "749184ba-d0a3-4a42-c184-795aa12f8244"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 84903\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13270\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='13270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/13270 39:30 < 12:55, 4.22 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.314400</td>\n",
       "      <td>0.265402</td>\n",
       "      <td>0.885704</td>\n",
       "      <td>0.885841</td>\n",
       "      <td>0.885985</td>\n",
       "      <td>0.885704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.341383</td>\n",
       "      <td>0.885421</td>\n",
       "      <td>0.885606</td>\n",
       "      <td>0.885805</td>\n",
       "      <td>0.885421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.561770</td>\n",
       "      <td>0.880800</td>\n",
       "      <td>0.881671</td>\n",
       "      <td>0.882834</td>\n",
       "      <td>0.880800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>0.743581</td>\n",
       "      <td>0.884572</td>\n",
       "      <td>0.883167</td>\n",
       "      <td>0.882473</td>\n",
       "      <td>0.884572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 10604\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./unsafe/FINAL_VERS/checkpoint-2500\n",
      "Configuration saved in ./unsafe/FINAL_VERS/checkpoint-2500/config.json\n",
      "Model weights saved in ./unsafe/FINAL_VERS/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in ./unsafe/FINAL_VERS/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ./unsafe/FINAL_VERS/checkpoint-2500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10604\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./unsafe/FINAL_VERS/checkpoint-5000\n",
      "Configuration saved in ./unsafe/FINAL_VERS/checkpoint-5000/config.json\n",
      "Model weights saved in ./unsafe/FINAL_VERS/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in ./unsafe/FINAL_VERS/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in ./unsafe/FINAL_VERS/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10604\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./unsafe/FINAL_VERS/checkpoint-7500\n",
      "Configuration saved in ./unsafe/FINAL_VERS/checkpoint-7500/config.json\n",
      "Model weights saved in ./unsafe/FINAL_VERS/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in ./unsafe/FINAL_VERS/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in ./unsafe/FINAL_VERS/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [unsafe/FINAL_VERS/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10604\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./unsafe/FINAL_VERS/checkpoint-10000\n",
      "Configuration saved in ./unsafe/FINAL_VERS/checkpoint-10000/config.json\n",
      "Model weights saved in ./unsafe/FINAL_VERS/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in ./unsafe/FINAL_VERS/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in ./unsafe/FINAL_VERS/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [unsafe/FINAL_VERS/checkpoint-7500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./unsafe/FINAL_VERS/checkpoint-2500 (score: 0.885840607944948).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10000, training_loss=0.14885815353393556, metrics={'train_runtime': 2371.06, 'train_samples_per_second': 179.04, 'train_steps_per_second': 5.597, 'total_flos': 1.0521975548256e+16, 'train_loss': 0.14885815353393556, 'epoch': 3.77})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "vcjYgdNl6kJq",
    "outputId": "ab9fdfb7-d08c-4fad-d14f-0b22a3a0f5fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 10565\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='331' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mTSb9Kv96krH",
    "outputId": "0eb5206b-4a8c-4953-95b5-25a008c9f2af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.8870807480153264\n",
      "recall 0.8874585896829152\n",
      "fscore_weighted 0.8872615700183797\n",
      "roc_auc 0.9391643004010369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92      7839\n",
      "           1       0.78      0.78      0.78      2726\n",
      "\n",
      "    accuracy                           0.89     10565\n",
      "   macro avg       0.85      0.85      0.85     10565\n",
      "weighted avg       0.89      0.89      0.89     10565\n",
      "\n",
      "   threshold    f1  prec   rec   acc\n",
      "4        0.4  0.89  0.75  0.82  0.88\n",
      "5        0.5  0.89  0.78  0.78  0.89\n",
      "6        0.6  0.88  0.82  0.72  0.89\n",
      "7        0.7  0.88  0.85  0.66  0.88\n",
      "3        0.3  0.87  0.70  0.86  0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8872615700183797"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "id": "aWOFQAKlp0yJ",
    "outputId": "4157a3b6-8e23-47ee-b936-28e0d29aa8f6"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-19-4f7e548e8412>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mwhile\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m==\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m   \u001B[0mi\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "while 1==1:\n",
    "  i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNnDNR1GDmyn",
    "outputId": "adc25c70-aa08-45e3-cc62-b8d41d00e81b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./unsafe/FINAL_VERS/checkpoint-10000/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"DeepPavlov/rubert-base-cased-conversational\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file ./unsafe/FINAL_VERS/checkpoint-10000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./unsafe/FINAL_VERS/checkpoint-10000/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "trained_model = BertForSequenceClassification.from_pretrained(\"../model/2/10000/\", local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Afc8LhD-FZVx",
    "outputId": "c7bd1c78-1f5e-4888-c299-0b8b3c9a8418"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file ./unsafe/FINAL_VERS/checkpoint-10000/added_tokens.json. We won't load it.\n",
      "Didn't find file ./unsafe/FINAL_VERS/checkpoint-10000/tokenizer.json. We won't load it.\n",
      "loading file ./unsafe/FINAL_VERS/checkpoint-10000/vocab.txt\n",
      "loading file None\n",
      "loading file ./unsafe/FINAL_VERS/checkpoint-10000/special_tokens_map.json\n",
      "loading file ./unsafe/FINAL_VERS/checkpoint-10000/tokenizer_config.json\n",
      "loading file None\n"
     ]
    }
   ],
   "source": [
    "trained_tokenizer = BertTokenizer.from_pretrained(\"../model/2/10000/\", local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "VjguP6LKFqS2"
   },
   "outputs": [],
   "source": [
    "encoded_input = trained_tokenizer(\"Боже мой, как же неприятно было в Афганистане. Ненавижу жару! Аллах Акбар\", return_tensors='pt')\n",
    "output = trained_model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G3LQ2GQzJm5F",
    "outputId": "bd8faf3e-fb31-4333-ed88-482b8bb3e056"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.get('logits').argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rYionURNNige",
    "outputId": "5a6b191e-febf-4f15-e087-2c1b36265cd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4403e-04, 9.9976e-01]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.get('logits').softmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h48v5ahWKnI3",
    "outputId": "a2b9e1f7-c927-4b94-9ac4-61aeda6301d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput([('logits',\n",
       "                           tensor([[-4.3503,  3.9677]], grad_fn=<AddmmBackward0>))])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zXcgqHFeBE4I",
    "outputId": "e393aba8-2573-454c-8897-1e20f62fb69b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/unsafe/ (stored 0%)\n",
      "  adding: content/unsafe/FINAL_VERS/ (stored 0%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-2500/ (stored 0%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-2500/special_tokens_map.json (deflated 40%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-2500/optimizer.pt (deflated 29%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-2500/tokenizer_config.json (deflated 38%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-2500/pytorch_model.bin (deflated 8%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-2500/scheduler.pt (deflated 49%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-2500/training_args.bin (deflated 49%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-2500/vocab.txt (deflated 65%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-2500/config.json (deflated 53%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-2500/trainer_state.json (deflated 53%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-2500/rng_state.pth (deflated 27%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-10000/ (stored 0%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-10000/special_tokens_map.json (deflated 40%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-10000/optimizer.pt (deflated 29%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-10000/tokenizer_config.json (deflated 38%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-10000/pytorch_model.bin (deflated 8%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-10000/scheduler.pt (deflated 49%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-10000/training_args.bin (deflated 49%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-10000/vocab.txt (deflated 65%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-10000/config.json (deflated 53%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-10000/trainer_state.json (deflated 70%)\n",
      "  adding: content/unsafe/FINAL_VERS/checkpoint-10000/rng_state.pth (deflated 27%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /content/file.zip /content/unsafe/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Correct_Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04be287a310d416bbb685fd8902c0fc0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e96feab70eb491bacfae4236dbf61b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45346c93451840b8bcce1a388e3d9690": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4ffe632561334d86849173ca7caa66e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e96feab70eb491bacfae4236dbf61b5",
      "placeholder": "​",
      "style": "IPY_MODEL_9a39210dc5804fa298cd9844b1510d11",
      "value": "Downloading: 100%"
     }
    },
    "5b81e7e5d1c44510a1d7499a7b6d9636": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6e4096557950488bb10e73010cc2246a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4ffe632561334d86849173ca7caa66e1",
       "IPY_MODEL_fcf2c07e4ea7497e8e3829b106fb5903",
       "IPY_MODEL_e29a1008dcc14277be4de71f50628774"
      ],
      "layout": "IPY_MODEL_88533516dfce441a8191ded1e9577ffc"
     }
    },
    "88533516dfce441a8191ded1e9577ffc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a39210dc5804fa298cd9844b1510d11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b08370db97714bb89899f698087c4dce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e29a1008dcc14277be4de71f50628774": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04be287a310d416bbb685fd8902c0fc0",
      "placeholder": "​",
      "style": "IPY_MODEL_45346c93451840b8bcce1a388e3d9690",
      "value": " 681M/681M [00:19&lt;00:00, 52.0MB/s]"
     }
    },
    "fcf2c07e4ea7497e8e3829b106fb5903": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b08370db97714bb89899f698087c4dce",
      "max": 714355318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5b81e7e5d1c44510a1d7499a7b6d9636",
      "value": 714355318
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}